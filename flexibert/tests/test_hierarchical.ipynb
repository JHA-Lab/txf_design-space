{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import yaml\n",
    "import json\n",
    "import numpy as np\n",
    "import random\n",
    "import subprocess\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "sys.path.append('../../embeddings/')\n",
    "sys.path.append('../../boshnas/')\n",
    "\n",
    "from library import Graph, GraphLib\n",
    "from boshnas import BOSHNAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Homogenous models: 13\n",
      "Heterogenous models: 44\n"
     ]
    }
   ],
   "source": [
    "trained_hashes = os.listdir('/scratch/gpfs/stuli/txf_design-space/models/glue/')\n",
    "\n",
    "graphLib = GraphLib.load_from_dataset('../../dataset/dataset_test_bn.json')\n",
    "\n",
    "def is_homogenous(graphObject):\n",
    "    model_dict = graphObject.model_dict\n",
    "    hashed_f = [hash(str(item)) for item in model_dict['f']]\n",
    "    return True if len(set(model_dict['h'])) == 1 and len(set(model_dict['n'])) == 1 and len(set(model_dict['o'])) == 1 \\\n",
    "        and len(set(hashed_f)) == 1 and len(set(model_dict['p'])) == 1 else False\n",
    "\n",
    "homogenous_models, heterogenous_models = 0, 0\n",
    "X_ds_total = np.zeros((len(trained_hashes), 16))\n",
    "y_ds_total = np.zeros((len(trained_hashes)))\n",
    "count = 0\n",
    "\n",
    "for model_hash in trained_hashes:\n",
    "    model, _ = graphLib.get_graph(model_hash=model_hash)\n",
    "    X_ds_total[count, :], y_ds_total[count] = model.embedding, \\\n",
    "        1 - json.load(open(f'/scratch/gpfs/stuli/txf_design-space/models/glue/{model_hash}/all_results.json'))['glue_score']\n",
    "    if is_homogenous(model):\n",
    "        homogenous_models += 1\n",
    "    else:\n",
    "        heterogenous_models += 1\n",
    "    count += 1\n",
    "        \n",
    "print(f'Homogenous models: {homogenous_models}\\nHeterogenous models: {heterogenous_models}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best design-space performance:  0.419\n",
      "Best model hash: 70d79a6325ce426644aed68b93a6d751bcf4dba5b38ced20024a06604b033da7\n",
      "Best model dict: {'l': 4, 'h': [256, 256, 256, 256], 'n': [4, 4, 2, 2], 'o': ['l', 'l', 'l', 'l'], 'f': [[1024], [1024], [512, 512, 512], [512, 512, 512]], 'p': ['dct', 'dct', 'dct', 'dct']}\n",
      "Best model is homogenous: False\n"
     ]
    }
   ],
   "source": [
    "print(f'Best design-space performance: {1 - np.amin(y_ds_total): 0.03f}')\n",
    "\n",
    "best_model_hash = trained_hashes[np.argmin(y_ds_total)]\n",
    "best_model, _ = graphLib.get_graph(model_hash=best_model_hash)\n",
    "\n",
    "print(f'Best model hash: {best_model_hash}')\n",
    "print(f'Best model dict: {best_model.model_dict}')\n",
    "\n",
    "print(f'Best model is homogenous: {is_homogenous(best_model)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 performances:\n",
      "{'l': 4, 'h': [256, 256, 256, 256], 'n': [4, 4, 2, 2], 'o': ['l', 'l', 'l', 'l'], 'f': [[1024], [1024], [512, 512, 512], [512, 512, 512]], 'p': ['dct', 'dct', 'dct', 'dct']}:\n",
      "\t0.41935307370178576\n",
      "{'l': 4, 'h': [256, 256, 256, 256], 'n': [4, 4, 2, 2], 'o': ['c', 'c', 'c', 'c'], 'f': [[512, 512, 512], [512, 512, 512], [1024, 1024, 1024], [1024, 1024, 1024]], 'p': [5, 5, 5, 5]}:\n",
      "\t0.41747407511343715\n",
      "{'l': 2, 'h': [128, 128], 'n': [4, 4], 'o': ['sa', 'sa'], 'f': [[1024], [1024]], 'p': ['sdp', 'sdp']}:\n",
      "\t0.41721479366960335\n",
      "{'l': 4, 'h': [256, 256, 256, 256], 'n': [2, 2, 2, 2], 'o': ['c', 'c', 'sa', 'sa'], 'f': [[1024, 1024, 1024], [1024, 1024, 1024], [512, 512, 512], [512, 512, 512]], 'p': [9, 9, 'wma', 'wma']}:\n",
      "\t0.41688767101809343\n",
      "{'l': 4, 'h': [128, 128, 256, 256], 'n': [4, 4, 2, 2], 'o': ['l', 'l', 'l', 'l'], 'f': [[1024], [1024], [512], [512]], 'p': ['dft', 'dft', 'dct', 'dct']}:\n",
      "\t0.41577651438604857\n",
      "{'l': 4, 'h': [128, 128, 256, 256], 'n': [4, 4, 2, 2], 'o': ['c', 'c', 'c', 'c'], 'f': [[1024], [1024], [1024, 1024, 1024], [1024, 1024, 1024]], 'p': [5, 5, 5, 5]}:\n",
      "\t0.4156894726529221\n",
      "{'l': 4, 'h': [256, 256, 256, 256], 'n': [2, 2, 4, 4], 'o': ['l', 'l', 'l', 'l'], 'f': [[1024], [1024], [1024], [1024]], 'p': ['dft', 'dft', 'dct', 'dct']}:\n",
      "\t0.4156452368498985\n",
      "{'l': 4, 'h': [256, 256, 256, 256], 'n': [2, 2, 4, 4], 'o': ['sa', 'sa', 'c', 'c'], 'f': [[512], [512], [512], [512]], 'p': ['wma', 'wma', 9, 9]}:\n",
      "\t0.41462579307261116\n",
      "{'l': 4, 'h': [256, 256, 128, 128], 'n': [2, 2, 4, 4], 'o': ['c', 'c', 'c', 'c'], 'f': [[512, 512, 512], [512, 512, 512], [512, 512, 512], [512, 512, 512]], 'p': [9, 9, 5, 5]}:\n",
      "\t0.41262272970390257\n",
      "{'l': 4, 'h': [128, 128, 256, 256], 'n': [2, 2, 2, 2], 'o': ['l', 'l', 'c', 'c'], 'f': [[512, 512, 512], [512, 512, 512], [1024], [1024]], 'p': ['dft', 'dft', 9, 9]}:\n",
      "\t0.41115260750401905\n"
     ]
    }
   ],
   "source": [
    "top_models = []\n",
    "\n",
    "print('Top 10 performances:')\n",
    "for i in range(10):\n",
    "    model_hash = trained_hashes[np.argsort(y_ds_total)[i]]\n",
    "    model, _ = graphLib.get_graph(model_hash=model_hash)\n",
    "    top_models.append(model)\n",
    "    \n",
    "    print(f'{model.model_dict}:\\n\\t{1 - y_ds_total[np.argsort(y_ds_total)[i]]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOP_NUM_MODELS = 5\n",
    "NUM_NEIGHBORS_FOR_INTERPOLATION = 10\n",
    "\n",
    "new_library = []\n",
    "\n",
    "graphLib_new = GraphLib('../../design_space/design_space_test.yaml')\n",
    "\n",
    "new_library = []\n",
    "\n",
    "for i in tqdm(range(TOP_NUM_MODELS), desc='Generating new library'):\n",
    "    num_neighbors = NUM_NEIGHBORS_FOR_INTERPOLATION # // (i+1)\n",
    "    for n in range(num_neighbors):\n",
    "        try:\n",
    "            new_library.extend(graphLib.interpolate_neighbors(top_models[i], \\\n",
    "                graphLib.get_graph(model_hash=top_models[i].neighbors[n])[0], 2, 1))\n",
    "        \n",
    "print('Length of new library: ', len(new_library))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashes = []\n",
    "\n",
    "reduced_library = []\n",
    "\n",
    "for n in tqdm(new_library, desc='Reducing new library'):\n",
    "    if n.hash in hashes: continue\n",
    "    hashes.append(n.hash)\n",
    "    reduced_library.append(n)\n",
    "    \n",
    "print('Length of reduced library: ', len(reduced_library))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphLib_new.library = reduced_library\n",
    "\n",
    "# Build embeddings\n",
    "graphLib_new.build_embeddings(16, algo='GD', kernel='GraphEditDistance', n_jobs=1)\n",
    "\n",
    "# Save dataset\n",
    "graphLib_new.save_dataset('../../dataset/dataset_test_bn_2.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "txf_design-space [~/.conda/envs/txf_design-space/]",
   "language": "python",
   "name": "conda_txf_design-space"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
